{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Stereo Calibration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "images = glob.glob(\"./imgs/original/calibration/left/*.jpg\")\n",
    "images.sort()\n",
    "i = 0\n",
    "for img_name in images:\n",
    "    img = cv2.imread(img_name)\n",
    "    img = cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))\n",
    "    cv2.imwrite(\"./imgs/scaled/calibration/left/\" + str(i + 1) + \".jpg\", img)\n",
    "    i += 1\n",
    "\n",
    "images = glob.glob(\"./imgs/original/calibration/right/*.jpg\")\n",
    "images.sort()\n",
    "i = 0\n",
    "for img_name in images:\n",
    "    img = cv2.imread(img_name)\n",
    "    img = cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))\n",
    "    cv2.imwrite(\"./imgs/scaled/calibration/right/\" + str(i + 1) + \".jpg\", img)\n",
    "    i += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# 设置寻找亚像素角点的参数，采用的停止准则是最大循环次数30和最大误差容限0.001\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 30, 0.001)\n",
    "\n",
    "# 获取标定板角点的位置\n",
    "objp = np.zeros((8 * 8, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:8, 0:8].T.reshape(-1, 2)  # 将世界坐标系建在标定板上，所有点的Z坐标全部为0，所以只需要赋值x和y\n",
    "\n",
    "obj_points = []  # 存储3D点\n",
    "left_img_points = []  # 存储左图2D点\n",
    "right_img_points = [] # 存储右图2D点\n",
    "\n",
    "# 获取对应文件夹下的所有图片，进行标定工作\n",
    "left_images = glob.glob(\"./imgs/scaled/calibration/left/*.jpg\")\n",
    "right_images = glob.glob(\"./imgs/scaled/calibration/right/*.jpg\")\n",
    "# 需要对图片进行排序，不然之后的绘制过程可能会因为乱序而没有效果\n",
    "left_images.sort()\n",
    "right_images.sort()\n",
    "\n",
    "assert len(left_images) == len(right_images)\n",
    "\n",
    "images_pair = zip(left_images, right_images)\n",
    "\n",
    "for l_img, r_img in images_pair:\n",
    "    left_img = cv2.imread(l_img)\n",
    "    left_gray = cv2.cvtColor(left_img, cv2.COLOR_BGR2GRAY)\n",
    "    l_size = left_gray.shape[::-1]\n",
    "    left_ret, left_corners = cv2.findChessboardCorners(left_gray, (8, 8), None)\n",
    "\n",
    "    right_img = cv2.imread(r_img)\n",
    "    right_gray = cv2.cvtColor(right_img, cv2.COLOR_BGR2GRAY)\n",
    "    r_size = right_gray.shape[::-1]\n",
    "    right_ret, right_corners = cv2.findChessboardCorners(right_gray, (8, 8), None)\n",
    "\n",
    "    if left_ret and right_ret:\n",
    "        obj_points.append(objp)\n",
    "        # Right points\n",
    "        right_corners2 = cv2.cornerSubPix(right_gray, right_corners, (5, 5), (-1, -1), criteria)\n",
    "        right_img_points.append(right_corners2)\n",
    "\n",
    "        # Left points\n",
    "        left_corners2 = cv2.cornerSubPix(left_gray, left_corners, (5, 5), (-1, -1), criteria)\n",
    "        left_img_points.append(left_corners2)\n",
    "    else:\n",
    "        print(\"Couldn't find chessboard on \" + l_img + \" and \" + r_img)\n",
    "        break\n",
    "\n",
    "l_ret, l_mtx, l_dist, _, _ = cv2.calibrateCamera(obj_points, left_img_points, l_size, None, None)\n",
    "r_ret, r_mtx, r_dist, _, _ = cv2.calibrateCamera(obj_points, right_img_points, r_size, None, None)\n",
    "\n",
    "i = 0\n",
    "pairs = zip(left_images, right_images)\n",
    "\n",
    "for l_img, r_img in pairs:\n",
    "    l_image = cv2.imread(l_img)\n",
    "    h, w = l_image.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(r_mtx, r_dist, (w, h), 1, (w, h))\n",
    "    l_dst = cv2.undistort(l_image, r_mtx, r_dist, None, newcameramtx)\n",
    "    cv2.imwrite(\"./imgs/scaled/calibration_result/left/\" + str(i + 1) + \".jpg\", l_dst)\n",
    "    r_image = cv2.imread(r_img)\n",
    "    h, w = r_image.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(r_mtx, r_dist, (w, h), 1, (w, h))\n",
    "    r_dst = cv2.undistort(r_image, r_mtx, r_dist, None, newcameramtx)\n",
    "    cv2.imwrite(\"./imgs/scaled/calibration_result/right/\" + str(i + 1) + \".jpg\", r_dst)\n",
    "\n",
    "    i = i + 1\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Stereo Calibration\n",
    "\n",
    "flags = 0\n",
    "flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "# flags |= cv2.CALIB_SAME_FOCAL_LENGTH\n",
    "flags |= cv2.CALIB_FIX_FOCAL_LENGTH\n",
    "flags |= cv2.CALIB_FIX_ASPECT_RATIO\n",
    "flags |= cv2.CALIB_FIX_K1\n",
    "flags |= cv2.CALIB_FIX_K2\n",
    "flags |= cv2.CALIB_FIX_K3\n",
    "flags |= cv2.CALIB_FIX_K4\n",
    "flags |= cv2.CALIB_FIX_K5\n",
    "\n",
    "stereo_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)\n",
    "\n",
    "\n",
    "ret, Camera1Mat, Dist1, Camera2Mat, Dist2, R, T, E, F = cv2.stereoCalibrate(obj_points, left_img_points, right_img_points,\n",
    "                                                                            l_mtx, l_dist, r_mtx, r_dist, imageSize=l_size,\n",
    "                                                                            criteria=stereo_criteria, flags = flags)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "print(Camera1Mat)\n",
    "print(Camera2Mat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[435.73720578   0.         345.51108921]\n",
      " [  0.         436.80091531 238.25453162]\n",
      " [  0.           0.           1.        ]]\n",
      "[[568.06867976   0.         374.53265488]\n",
      " [  0.         572.4684764  242.78889177]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# Show a result\n",
    "img_L = cv2.imread(\"./imgs/scaled/calibration_result/left/1.jpg\")\n",
    "img_R = cv2.imread(\"./imgs/scaled/calibration_result/right/1.jpg\")\n",
    "\n",
    "img_size = img_L.shape[:2][::-1]\n",
    "\n",
    "R1, R2, P1, P2, Q, roi_left, roi_right = cv2.stereoRectify(Camera1Mat, Dist1, Camera2Mat, Dist2, img_size, R, T, flags = 1)\n",
    "left_map1, left_map2 = cv2.initUndistortRectifyMap(Camera1Mat, Dist1, R1, P1, img_size, cv2.CV_16SC2)\n",
    "right_map1, right_map2 = cv2.initUndistortRectifyMap(Camera2Mat, Dist2, R2, P2, img_size, cv2.CV_16SC2)\n",
    "\n",
    "\n",
    "result_l = cv2.remap(img_L, left_map1, left_map2, cv2.INTER_LINEAR)\n",
    "result_r = cv2.remap(img_R, left_map1, left_map2, cv2.INTER_LINEAR)\n",
    "\n",
    "result = np.concatenate((result_l, result_r), axis=1)\n",
    "# draw_lines(result)\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"result.jpg\", result)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "def draw_lines(img):\n",
    "    img_size = img.shape\n",
    "    ptsX = [i for i in range(0, img_size[0], img_size[0]//20)]\n",
    "    ptsY = [0, img_size[1]]\n",
    "    for i in range(len(ptsX)):\n",
    "        cv2.line(img, (ptsY[0], ptsX[i]), (ptsY[1], ptsX[i]), (0, 0, 255), 1, 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "result_l = cv2.imread(\"./imgs/scaled/calibration_result/left/1.jpg\")\n",
    "result_r = cv2.imread(\"./imgs/scaled/calibration_result/right/1.jpg\")\n",
    "\n",
    "result = np.concatenate((result_l, result_r), axis=1)\n",
    "draw_lines(result)\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"result.jpg\", result)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "ply_header = '''ply\n",
    "format ascii 1.0\n",
    "element vertex %(vert_num)d\n",
    "property float x\n",
    "property float y\n",
    "property float z\n",
    "property uchar red\n",
    "property uchar green\n",
    "property uchar blue\n",
    "end_header\n",
    "'''\n",
    "\n",
    "def write_ply(fn, verts, colors):\n",
    "    verts = verts.reshape(-1, 3)\n",
    "    colors = colors.reshape(-1, 3)\n",
    "    verts = np.hstack([verts, colors])\n",
    "    with open(fn, 'wb') as f:\n",
    "        f.write((ply_header % dict(vert_num=len(verts))).encode('utf-8'))\n",
    "        np.savetxt(f, verts, fmt='%f %f %f %d %d %d ')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# disparity range is tuned for 'aloe' image pair\n",
    "window_size = 3\n",
    "min_disp = 16\n",
    "num_disp = 72-min_disp\n",
    "stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "    numDisparities = num_disp,\n",
    "    blockSize = 4,\n",
    "    P1 = 8*3*window_size**2,\n",
    "    P2 = 32*3*window_size**2,\n",
    "    disp12MaxDiff = 50,\n",
    "    uniquenessRatio = 10,\n",
    "    speckleWindowSize = 100,\n",
    "    speckleRange = 32\n",
    ")\n",
    "\n",
    "print('computing disparity...')\n",
    "disp = stereo.compute(result_l, result_r).astype(np.float32) / 16.0\n",
    "\n",
    "print('generating 3d point cloud...',)\n",
    "# Q = np.float32([[1, 0, 0, 0],\n",
    "#                 [0, 1, 0, 0], # turn points 180 deg around x-axis,\n",
    "#                 [0, 0, 1, 0], # so that y-axis looks up\n",
    "#                 [0, 0, 0, 1]])\n",
    "\n",
    "f = 0.8*w                          # guess for focal length\n",
    "Q = np.float32([[1, 0, 0, -0.5*w],\n",
    "                [0,-1, 0,  0.5*h], # turn points 180 deg around x-axis,\n",
    "                [0, 0, 0,     -f], # so that y-axis looks up\n",
    "                [0, 0, 1,      0]])\n",
    "points = cv2.reprojectImageTo3D(disp, Q)\n",
    "colors = cv2.cvtColor(result_l, cv2.COLOR_BGR2RGB)\n",
    "mask = disp > disp.min()\n",
    "out_points = points[mask]\n",
    "out_colors = colors[mask]\n",
    "out_fn = 'out.ply'\n",
    "write_ply(out_fn, out_points, out_colors)\n",
    "print('%s saved' % out_fn)\n",
    "\n",
    "cv2.imshow('left', result_l)\n",
    "cv2.imshow('disparity', (disp-min_disp)/num_disp)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('Done')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "computing disparity...\n",
      "generating 3d point cloud...\n",
      "out.ply saved\n",
      "Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('cv_envs': conda)"
  },
  "interpreter": {
   "hash": "40a5ed5a0e8a82d9f717d1d726f8aadf269eda72e1afc8b608d12bc7579c9dc4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}