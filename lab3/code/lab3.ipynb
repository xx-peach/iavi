{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereo Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize all images photoed by left camera\n",
    "images = glob.glob(\"../../../images/lab3/origin/left/*.png\")\n",
    "images.sort()\n",
    "i = 0\n",
    "for img_name in images:\n",
    "    img = cv2.imread(img_name)\n",
    "    img = cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))\n",
    "    cv2.imwrite(\"../../../images/lab3/scaled/calibration/left/\" + str(i + 1) + \".jpg\", img)\n",
    "    i += 1\n",
    "\n",
    "# resize all images photoed by right camera\n",
    "images = glob.glob(\"../../../images/lab3/origin/right/*.png\")\n",
    "images.sort()\n",
    "i = 0\n",
    "for img_name in images:\n",
    "    img = cv2.imread(img_name)\n",
    "    img = cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))\n",
    "    cv2.imwrite(\"../../../images/lab3/scaled/calibration/right/\" + str(i + 1) + \".jpg\", img)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置寻找亚像素角点的参数，采用的停止准则是最大循环次数30和最大误差容限0.001\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 30, 0.001)\n",
    "\n",
    "# 获取标定板角点的位置\n",
    "objp = np.zeros((8 * 8, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:8, 0:8].T.reshape(-1, 2)  # 将世界坐标系建在标定板上，所有点的Z坐标全部为0，所以只需要赋值x和y\n",
    "\n",
    "obj_points = []         # 存储3D点\n",
    "left_img_points = []    # 存储左图2D点\n",
    "right_img_points = []   # 存储右图2D点\n",
    "\n",
    "# 获取对应文件夹下的所有图片，进行标定工作\n",
    "left_images = glob.glob(\"../../../images/lab3/scaled/calibration/left/*.jpg\")\n",
    "right_images = glob.glob(\"../../../images/lab3/scaled/calibration/right/*.jpg\")\n",
    "\n",
    "# 需要对图片进行排序，不然之后的绘制过程可能会因为乱序而没有效果\n",
    "left_images.sort()\n",
    "right_images.sort()\n",
    "\n",
    "assert len(left_images) == len(right_images)\n",
    "\n",
    "images_pair = zip(left_images, right_images)\n",
    "for l_img, r_img in images_pair:\n",
    "    # finds the positions of internal corners of the chessboard of the left images\n",
    "    left_img = cv2.imread(l_img)\n",
    "    left_gray = cv2.cvtColor(left_img, cv2.COLOR_BGR2GRAY)\n",
    "    l_size = left_gray.shape[::-1]\n",
    "    left_ret, left_corners = cv2.findChessboardCorners(left_gray, (8, 8), None)\n",
    "    # finds the positions of internal corners of the chessboard of the right images\n",
    "    right_img = cv2.imread(r_img)\n",
    "    right_gray = cv2.cvtColor(right_img, cv2.COLOR_BGR2GRAY)\n",
    "    r_size = right_gray.shape[::-1]\n",
    "    right_ret, right_corners = cv2.findChessboardCorners(right_gray, (8, 8), None)\n",
    "\n",
    "    if left_ret and right_ret:\n",
    "        # append the world coordinate of the standard chessboard\n",
    "        obj_points.append(objp)\n",
    "        # fines the corner locations of the left images' points\n",
    "        left_corners2 = cv2.cornerSubPix(left_gray, left_corners, (5, 5), (-1, -1), criteria)\n",
    "        left_img_points.append(left_corners2)\n",
    "        # fines the corner locations of the right images' points\n",
    "        right_corners2 = cv2.cornerSubPix(right_gray, right_corners, (5, 5), (-1, -1), criteria)\n",
    "        right_img_points.append(right_corners2)\n",
    "    else:\n",
    "        print(\"couldn't find chessboard on \" + l_img + \" and \" + r_img)\n",
    "        break\n",
    "\n",
    "l_ret, l_mtx, l_dist, _, _ = cv2.calibrateCamera(obj_points, left_img_points, l_size, None, None)\n",
    "r_ret, r_mtx, r_dist, _, _ = cv2.calibrateCamera(obj_points, right_img_points, r_size, None, None)\n",
    "\n",
    "i = 0\n",
    "pairs = zip(left_images, right_images)\n",
    "for l_img, r_img in pairs:\n",
    "    l_image = cv2.imread(l_img)\n",
    "    h, w = l_image.shape[:2]\n",
    "    # returns the new camera matrix of left camera based on the free scaling parameter\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(r_mtx, r_dist, (w, h), 1, (w, h))\n",
    "    l_dst = cv2.undistort(l_image, r_mtx, r_dist, None, newcameramtx)\n",
    "    cv2.imwrite(\"../../../images/lab3/scaled/calibration_result/left/\" + str(i + 1) + \".jpg\", l_dst)\n",
    "    r_image = cv2.imread(r_img)\n",
    "    h, w = r_image.shape[:2]\n",
    "    # returns the new camera matrix of right camera based on the free scaling parameter\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(r_mtx, r_dist, (w, h), 1, (w, h))\n",
    "    r_dst = cv2.undistort(r_image, r_mtx, r_dist, None, newcameramtx)\n",
    "    cv2.imwrite(\"../../../images/lab3/scaled/calibration_result/right/\" + str(i + 1) + \".jpg\", r_dst)\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stereo Calibration\n",
    "\n",
    "flags = 0\n",
    "flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "# flags |= cv2.CALIB_SAME_FOCAL_LENGTH\n",
    "flags |= cv2.CALIB_FIX_FOCAL_LENGTH\n",
    "flags |= cv2.CALIB_FIX_ASPECT_RATIO\n",
    "flags |= cv2.CALIB_FIX_K1\n",
    "flags |= cv2.CALIB_FIX_K2\n",
    "flags |= cv2.CALIB_FIX_K3\n",
    "flags |= cv2.CALIB_FIX_K4\n",
    "flags |= cv2.CALIB_FIX_K5\n",
    "\n",
    "stereo_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)\n",
    "\n",
    "ret, Camera1Mat, Dist1, Camera2Mat, Dist2, R, T, E, F = cv2.stereoCalibrate(obj_points, left_img_points, right_img_points,\n",
    "                                                                            l_mtx, l_dist, r_mtx, r_dist, imageSize=l_size,\n",
    "                                                                            criteria=stereo_criteria, flags = flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a result\n",
    "img_L = cv2.imread(\"../../../images/lab3/scaled/calibration_result/left/1.jpg\")\n",
    "img_R = cv2.imread(\"../../../images/lab3/scaled/calibration_result/right/1.jpg\")\n",
    "\n",
    "img_size = img_L.shape[:2][::-1]\n",
    "\n",
    "R1, R2, P1, P2, Q, roi_left, roi_right = cv2.stereoRectify(Camera1Mat, Dist1, Camera2Mat, Dist2, img_size, R, T, flags = 1)\n",
    "left_map1, left_map2 = cv2.initUndistortRectifyMap(Camera1Mat, Dist1, R1, P1, img_size, cv2.CV_16SC2)\n",
    "right_map1, right_map2 = cv2.initUndistortRectifyMap(Camera2Mat, Dist2, R2, P2, img_size, cv2.CV_16SC2)\n",
    "\n",
    "result_l = cv2.remap(img_L, left_map1, left_map2, cv2.INTER_LINEAR)\n",
    "result_r = cv2.remap(img_R, left_map1, left_map2, cv2.INTER_LINEAR)\n",
    "\n",
    "result = np.concatenate((result_l, result_r), axis=1)\n",
    "# draw_lines(result)\n",
    "# cv2.imshow(\"result\", result)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite(\"result.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img):\n",
    "    img_size = img.shape\n",
    "    ptsX = [i for i in range(0, img_size[0], img_size[0]//20)]\n",
    "    ptsY = [0, img_size[1]]\n",
    "    for i in range(len(ptsX)):\n",
    "        cv2.line(img, (ptsY[0], ptsX[i]), (ptsY[1], ptsX[i]), (0, 0, 255), 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_l = cv2.imread(\"../../../images/lab3/scaled/calibration_result/left/1.jpg\")\n",
    "result_r = cv2.imread(\"../../../images/lab3/scaled/calibration_result/right/1.jpg\")\n",
    "\n",
    "result = np.concatenate((result_l, result_r), axis=1)\n",
    "draw_lines(result)\n",
    "# cv2.imshow(\"result\", result)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imwrite(\"result.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "ply_header = '''ply\n",
    "format ascii 1.0\n",
    "element vertex %(vert_num)d\n",
    "property float x\n",
    "property float y\n",
    "property float z\n",
    "property uchar red\n",
    "property uchar green\n",
    "property uchar blue\n",
    "end_header\n",
    "'''\n",
    "\n",
    "def write_ply(fn, verts, colors):\n",
    "    verts = verts.reshape(-1, 3)\n",
    "    colors = colors.reshape(-1, 3)\n",
    "    verts = np.hstack([verts, colors])\n",
    "    with open(fn, 'wb') as f:\n",
    "        f.write((ply_header % dict(vert_num=len(verts))).encode('utf-8'))\n",
    "        np.savetxt(f, verts, fmt='%f %f %f %d %d %d ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images...\n",
      "computing disparity...\n",
      "generating 3d point cloud...\n",
      "out_left.ply saved\n",
      "out_right.ply saved\n",
      "out_avg.ply saved\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "    print('loading images...')\n",
    "    imgL = cv.imread('./cupL.png')\n",
    "    imgR = cv.imread('./cupR.png')\n",
    "    imgL = cv.resize(imgL, (imgL.shape[1] // 2, imgL.shape[0] // 2))\n",
    "    imgR = cv.resize(imgR, (imgR.shape[1] // 2, imgR.shape[0] // 2))\n",
    "    imgL = cv.pyrDown(imgL)\n",
    "    imgR = cv.pyrDown(imgR)\n",
    "    # imgL = cv.pyrDown(cv.imread(cv.samples.findFile('aloeL.jpg')))  # downscale images for faster processing\n",
    "    # imgR = cv.pyrDown(cv.imread(cv.samples.findFile('aloeR.jpg')))\n",
    "\n",
    "    # disparity range is tuned for 'aloe' image pair\n",
    "    window_size = 11\n",
    "    min_disp = 16\n",
    "    num_disp = 128 - min_disp\n",
    "    stereo = cv.StereoSGBM_create(minDisparity = min_disp,\n",
    "        numDisparities = num_disp,\n",
    "        blockSize = 8,\n",
    "        P1 = 8*3*window_size**2,\n",
    "        P2 = 32*3*window_size**2,\n",
    "        disp12MaxDiff = 1,\n",
    "        uniquenessRatio = 10,\n",
    "        speckleWindowSize = 100,\n",
    "        speckleRange = 32\n",
    "    )\n",
    "\n",
    "    print('computing disparity...')\n",
    "    disp = stereo.compute(imgL, imgR).astype(np.float32) / 16.0\n",
    "\n",
    "    print('generating 3d point cloud...',)\n",
    "    h, w = imgL.shape[:2]\n",
    "    # f = 0.8*w                          # guess for focal length\n",
    "    f = 394.59508339\n",
    "    Q = np.float32([[1, 0,  0, -0.5*w],\n",
    "                    [0, -1, 0, 0.5*h], # turn points 180 deg around x-axis,\n",
    "                    [0, 0,  0, -f], # so that y-axis looks up\n",
    "                    [0, 0, 1, 0]])\n",
    "    # Q = np.float32([[1, 0, 0, 0],\n",
    "    #             [0, -1, 0, 0], # turn points 180 deg around x-axis,\n",
    "    #             [0, 0, 0, -f], # so that y-axis looks up\n",
    "    #             [0, 0, 1, 0]])\n",
    "    # Q = np.float32([[1, 0, 0, 0],\n",
    "    #                 [0, 1, 0, 0],\n",
    "    #                 [0, 0, 1, 0],\n",
    "    #                 [0, 0, 0, 1]])\n",
    "    points = cv.reprojectImageTo3D(disp, Q)\n",
    "\n",
    "    # Color discrepancy\n",
    "\n",
    "    # Use left image to color the model\n",
    "    colors = cv.cvtColor(imgL, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    # Use right image\n",
    "    colors1 = cv.cvtColor(imgR, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform the 'averaging' process of colors\n",
    "    img_avg = np.zeros_like(imgL)\n",
    "    for i in range(3):\n",
    "        U_L, D_L, V_L = np.linalg.svd(imgL[:, :, i])\n",
    "        U_R, D_R, V_R = np.linalg.svd(imgR[:, :, i])\n",
    "        avg_D = np.zeros((U_L.shape[1], V_L.shape[0]))\n",
    "        avg_D[:D_L.shape[0], :D_L.shape[0]] = np.diag((D_L + D_R)/2)\n",
    "        img_avg[:, :, i] = np.matmul(U_L, avg_D).dot(V_L)\n",
    "    # Use avg color\n",
    "    colors2 = cv.cvtColor(img_avg, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    mask = disp > disp.min()\n",
    "    out_points = points[mask]\n",
    "\n",
    "    out_colors = colors[mask]\n",
    "    out_colors1 = colors1[mask]\n",
    "    out_colors2 = colors2[mask]\n",
    "\n",
    "    out_fn = 'out_left.ply'\n",
    "    write_ply(out_fn, out_points, out_colors)\n",
    "    print('%s saved' % out_fn)\n",
    "\n",
    "    out_fn = 'out_right.ply'\n",
    "    write_ply(out_fn, out_points, out_colors1)\n",
    "    print('%s saved' % out_fn)\n",
    "\n",
    "    out_fn = 'out_avg.ply'\n",
    "    write_ply(out_fn, out_points, out_colors2)\n",
    "    print('%s saved' % out_fn)\n",
    "\n",
    "    # cv.imshow('left', imgL)\n",
    "    cv.imshow('disparity', (disp-min_disp)/num_disp)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12a5887d0bb5e6f7f12af69279d35b5497f5fec356987c05c6698d8be467ff84"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('cv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
